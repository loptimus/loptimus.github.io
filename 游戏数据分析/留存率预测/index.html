<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta name="generator" content="Hexo 3.9.0"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="X-UA-Compatible" content="IE=edge"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0"><link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222"><link rel="stylesheet" href="/css/main.css?v=7.3.0"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2"><script id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.3.0",sidebar:{position:"left",display:"post",offset:12,onmobile:!1},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},copycode:{enable:!1,show_result:!1,style:null},fancybox:!1,mediumzoom:!0,lazyload:!0,pangu:!1,algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},search:{root:"/",path:"search.xml"},tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"}}</script><meta name="description" content="留存率预测"><meta name="keywords" content="R语言,非线性回归"><meta property="og:type" content="article"><meta property="og:title" content="留存率预测"><meta property="og:url" content="http://yoursite.com/游戏数据分析/留存率预测/index.html"><meta property="og:site_name" content="QuickNotes"><meta property="og:description" content="留存率预测"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2019-02-25T16:01:03.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="留存率预测"><meta name="twitter:description" content="留存率预测"><link rel="canonical" href="http://yoursite.com/游戏数据分析/留存率预测/"><script id="page.configurations">CONFIG.page={sidebar:""}</script><title>留存率预测 | QuickNotes</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">QuickNotes</span><span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-toggle"> <button aria-label="切换导航栏"><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益 404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"> <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header> <a href="https://github.com/loptimus" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://yoursite.com/游戏数据分析/留存率预测/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="lwl"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="QuickNotes"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">留存率预测</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-02-25 18:34:47" itemprop="dateCreated datePublished" datetime="2019-02-25T18:34:47+08:00">2019-02-25</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-02-26 00:01:03" itemprop="dateModified" datetime="2019-02-26T00:01:03+08:00">2019-02-26</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/游戏数据分析/" itemprop="url" rel="index"><span itemprop="name">游戏数据分析</span></a></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> 阅读次数：<span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span></span><br><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span title="本文字数">6.6k</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="留存率预测">留存率预测</h1><a id="more"></a><p><strong>留存率</strong>指t日的新增用户，在t+n日再次登录游戏占t日新增用户的比例。</p><p>留存率预测是根据前期的留存率对给定自然时间内的留存率进行预测。假设某款游戏的留存率数据如下：</p><table><thead><tr class="header"><th>次日留存</th><th>3日留存率</th><th>7日留存率</th><th>14日留存率</th><th>30日留存率</th></tr></thead><tbody><tr class="odd"><td>0.1694</td><td>0.0980</td><td>0.0544</td><td>0.298</td><td>0.0149</td></tr></tbody></table><h2 id="探索性分析">探索性分析</h2><p>假设将留存日day作为自变量，留存率ratio看作自变量，绘制散点图。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入数据留存率数据</span></span><br><span class="line">ratio &lt;- c(<span class="number">0.1694</span>, <span class="number">0.0980</span>, <span class="number">0.0544</span>, <span class="number">0.0298</span>, <span class="number">0.0149</span>) </span><br><span class="line">day &lt;- c(<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">14</span>, <span class="number">30</span>)</span><br><span class="line"><span class="comment"># 绘制数据点图</span></span><br><span class="line">plot(day, ratio)</span><br><span class="line">lines(day, ratio)</span><br></pre></td></tr></table></figure> <img title="留存率散点图" data-src="/游戏数据分析/留存率预测/retention.png"><p>从图中的散点之间的连线可以看到，两者间可能存在某种曲线关系。因此，我们假设两个变量满足某种曲线关系，并对该曲线关系拟合一个曲线模型，然后对曲线模型的显著性进行检验。若检验为显著的，则使用该曲线模型对新增用户在接下来365日每天的留存率进行预测。</p><p>根据散点图中的曲线关系的形态，再结合已知的常见的曲线模型，我们选择以下函数对曲线进行拟合 <span class="math display">\[ \begin{align*} &amp;1. y = a * x ^ b \\ &amp;2. \frac{1}{y} = a + \frac{b}{x},(a&gt;0,b&lt;0) \\ &amp;3. y = a + blnx,(b &lt; 0) \\ &amp;4. y = ae^\frac{b}{x}, (b &gt; 0) \\ &amp;5. y = ae^{bx}, (b &lt; 0 ) \end{align*} \]</span> 所以接下来要对自变量day（<span class="math inline">\(x\)</span>）和因变量ratio（<span class="math inline">\(y\)</span>）的曲线关系能否使用上面的函数拟合进行显著性检验。因为在数据挖掘和机器学习中，习惯将拟合称为回归，并且为了与以下介绍的R环境中的函数区别开来，将上述拟合函数称为回归模型，函数的系数称为模型的回归系数。</p><h2 id="建立模型">建立模型</h2><p>对于day和ratio的曲线关系使用上述模型进行拟合的检验，首先分别对每个模型求出其回归系数（a和b）的估计值，然后再对得到回归系数估计值的模型进行显著性检验。由于上述模型都是非线性，所以可以使用非线性最小二乘法的方式求出上述模型的回归系数的估计值，再使用t检验进行显著性检验。</p><p>在R环境中，提供了nls函数（Nonlinear Least Squares，非线性最小二乘），该函数默认使用Gauss-Newton（高斯-牛顿）迭代法对模型参数进行求解，并给出显著性检验结果。</p><blockquote><p>高斯-牛顿迭代法的基本思想是使用泰勒级数展开式去近似地代替非线性回归模型，然后通过多次迭代修正回归系数，使回归系数不断逼近使非线性回归模型残差平方和达到最小的回归系数。</p></blockquote><ol type="1"><li>建立模型</li></ol><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 建立非线性回归</span></span><br><span class="line"><span class="comment"># 对应上述的模型1</span></span><br><span class="line">model1 &lt;- nls(ratio ~ a * day^b, start = list(a = <span class="number">1</span>, b = <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 对应上述的模型2</span></span><br><span class="line">model2 &lt;- nls(ratio ~ <span class="number">1</span> / (a + b / day), start = list(a = <span class="number">1</span>, b = <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 对应上述的模型3</span></span><br><span class="line">model3 &lt;- nls(ratio ~ a + b * log(day), start = list(a = <span class="number">1</span>, b = -<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 对应上述的模型4</span></span><br><span class="line">model4 &lt;- nls(ratio ~ a * exp(b / day), start = list(a = <span class="number">1</span>, b = <span class="number">1</span>))  </span><br><span class="line"><span class="comment"># 对应上述的模型5</span></span><br><span class="line">model5 &lt;- nls(ratio ~ a * exp(b * day), start = list(a = <span class="number">1</span>, b = -<span class="number">1</span>))</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>查看模型结果</li></ol><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型列表</span></span><br><span class="line">fit.model &lt;- list(fit1, fit2, fit3, fit4, fit5)</span><br><span class="line"><span class="comment"># 查看所有模型结果</span></span><br><span class="line">lapply(fit.model, summary)</span><br><span class="line"><span class="comment"># 获得模型的拟合值</span></span><br><span class="line">fit.values &lt;- lapply(fit.model, fitted.values)</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>]]</span><br><span class="line">Formula: ratio ~ a * day^b</span><br><span class="line">Parameters:</span><br><span class="line">   Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">a  <span class="number">0.172523</span>   <span class="number">0.007393</span>   <span class="number">23.34</span> <span class="number">0.000172</span> ***</span><br><span class="line">b -<span class="number">0.604448</span>   <span class="number">0.047449</span>  -<span class="number">12.74</span> <span class="number">0.001044</span> ** </span><br><span class="line">---</span><br><span class="line">Signif. codes:  <span class="number">0</span> ‘***’ <span class="number">0.001</span> ‘**’ <span class="number">0.01</span> ‘*’ <span class="number">0.05</span> ‘.’ <span class="number">0.1</span> ‘ ’ <span class="number">1</span></span><br><span class="line">Residual standard error: <span class="number">0.007621</span> on <span class="number">3</span> degrees of freedom</span><br><span class="line">Number of iterations to convergence: <span class="number">9</span> </span><br><span class="line">Achieved convergence tolerance: <span class="number">3.679e-06</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">2</span>]]</span><br><span class="line">Formula: ratio ~ <span class="number">1</span>/(a + b/day)</span><br><span class="line">Parameters:</span><br><span class="line">  Estimate Std. Error t value Pr(&gt;|t|)  </span><br><span class="line">a   <span class="number">22.296</span>      <span class="number">7.040</span>   <span class="number">3.167</span>   <span class="number">0.0506</span> .</span><br><span class="line">b  -<span class="number">16.443</span>      <span class="number">7.149</span>  -<span class="number">2.300</span>   <span class="number">0.1050</span>  </span><br><span class="line">---</span><br><span class="line">Signif. codes:  <span class="number">0</span> ‘***’ <span class="number">0.001</span> ‘**’ <span class="number">0.01</span> ‘*’ <span class="number">0.05</span> ‘.’ <span class="number">0.1</span> ‘ ’ <span class="number">1</span></span><br><span class="line">Residual standard error: <span class="number">0.03043</span> on <span class="number">3</span> degrees of freedom</span><br><span class="line">Number of iterations to convergence: <span class="number">9</span> </span><br><span class="line">Achieved convergence tolerance: <span class="number">3.407e-06</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">3</span>]]</span><br><span class="line">Formula: ratio ~ a + b * log(day)</span><br><span class="line">Parameters:</span><br><span class="line">   Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">a  <span class="number">0.156923</span>   <span class="number">0.011924</span>  <span class="number">13.160</span> <span class="number">0.000948</span> ***</span><br><span class="line">b -<span class="number">0.046024</span>   <span class="number">0.005497</span>  -<span class="number">8.372</span> <span class="number">0.003573</span> ** </span><br><span class="line">---</span><br><span class="line">Signif. codes:  <span class="number">0</span> ‘***’ <span class="number">0.001</span> ‘**’ <span class="number">0.01</span> ‘*’ <span class="number">0.05</span> ‘.’ <span class="number">0.1</span> ‘ ’ <span class="number">1</span></span><br><span class="line">Residual standard error: <span class="number">0.01456</span> on <span class="number">3</span> degrees of freedom</span><br><span class="line">Number of iterations to convergence: <span class="number">1</span> </span><br><span class="line">Achieved convergence tolerance: <span class="number">2.373e-07</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">4</span>]]</span><br><span class="line">Formula: ratio ~ a * exp(b/day)</span><br><span class="line">Parameters:</span><br><span class="line">  Estimate Std. Error t value Pr(&gt;|t|)  </span><br><span class="line">a  <span class="number">0.03966</span>    <span class="number">0.01256</span>   <span class="number">3.158</span>    <span class="number">0.051</span> .</span><br><span class="line">b  <span class="number">1.47450</span>    <span class="number">0.36370</span>   <span class="number">4.054</span>    <span class="number">0.027</span> *</span><br><span class="line">---</span><br><span class="line">Signif. codes:  <span class="number">0</span> ‘***’ <span class="number">0.001</span> ‘**’ <span class="number">0.01</span> ‘*’ <span class="number">0.05</span> ‘.’ <span class="number">0.1</span> ‘ ’ <span class="number">1</span></span><br><span class="line">Residual standard error: <span class="number">0.02623</span> on <span class="number">3</span> degrees of freedom</span><br><span class="line">Number of iterations to convergence: <span class="number">6</span> </span><br><span class="line">Achieved convergence tolerance: <span class="number">2.084e-06</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">5</span>]]</span><br><span class="line">Formula: ratio ~ a * exp(b * day)</span><br><span class="line">Parameters:</span><br><span class="line">  Estimate Std. Error t value Pr(&gt;|t|)   </span><br><span class="line">a  <span class="number">0.19269</span>    <span class="number">0.02129</span>   <span class="number">9.050</span>  <span class="number">0.00285</span> **</span><br><span class="line">b -<span class="number">0.18029</span>    <span class="number">0.03914</span>  -<span class="number">4.607</span>  <span class="number">0.01924</span> * </span><br><span class="line">---</span><br><span class="line">Signif. codes:  <span class="number">0</span> ‘***’ <span class="number">0.001</span> ‘**’ <span class="number">0.01</span> ‘*’ <span class="number">0.05</span> ‘.’ <span class="number">0.1</span> ‘ ’ <span class="number">1</span></span><br><span class="line">Residual standard error: <span class="number">0.01502</span> on <span class="number">3</span> degrees of freedom</span><br><span class="line">Number of iterations to convergence: <span class="number">12</span> </span><br><span class="line">Achieved convergence tolerance: <span class="number">7.599e-06</span></span><br></pre></td></tr></table></figure><p>上述输出中，有5个输出结果，分别对应于相应的函数模型。可以看到，每个输出结果的组成部分都是一样的。</p><ul><li>Formula：formula对象，即回归模型的表示方法</li><li>Parameters：回归系数相关信息<ul><li>Estimate：相应回归系数的估计值</li><li>Std. Error：相应回归系数的标准误</li><li>t value：相应回归系数的t检验量的值</li><li>Pr(&gt;|t|)：相应回归系数的t检验的检验的p值，用于判定显著性</li></ul></li><li>Signif. codes：显著性标识，检验的p值（这里对应于Pr(&gt;|t|)）越小，越显著。前面的数值（0, 0.001, 0.01等）表示相应的显著性水平。</li><li>Residual standard error：表示残差标准误；degrees of freedom为自由度，残差的自由度等于样本容量减2。这里样本容量为5，所以残差自由度为3。</li><li>Number of iterations to convergence：满足相应的满足逼近容忍度时的迭代次数</li><li>Achieved convergence tolerance：容忍度</li></ul><p>在输出结果中，若指定显著性水平为0.05，可以看到模型2的回归系数b和模型4的回归系数a是不显著的，即认为在显著性水平为0.05的情况下，模型2和模型4不满足回归的假设，所以将选择剩余的模型进行比较。</p><h2 id="模型比较">模型比较</h2><p>通过上面求出的模型的回归系数，得到以下3个回归模型： <span class="math display">\[ \begin{align*} &amp;1. y = a * x ^ b \\ &amp;3. y = a + blnx,(b &lt; 0) \\ &amp;5. y = ae^{bx}, (b &lt; 0 ) \end{align*} \]</span> 比较这3个模型的决定系数<span class="math inline">\(R^2\)</span>和残差标准误<span class="math inline">\(s\)</span>这两个标准，选择拟合程度更好的模型。</p><blockquote><p><strong>决定系数<span class="math inline">\(R^2\)</span></strong>越大，说明残差越小，回归曲线拟合越好，<span class="math inline">\(R^2\)</span>从总体上给出一个拟合好坏程度的度量。</p><p><strong>残差标准误<span class="math inline">\(s\)</span></strong>为诸观测值与由曲线给出的拟合值之间的平均偏离程度的度量，<span class="math inline">\(s\)</span>越小，方程越好</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ModelMeasure &lt;- <span class="keyword">function</span>(fit.value, y) &#123;</span><br><span class="line">  <span class="comment"># 决定系数</span></span><br><span class="line">  r.square &lt;- <span class="number">1</span> - sum((y - fit.value)^<span class="number">2</span>) / sum((y - mean(y))^<span class="number">2</span>)</span><br><span class="line">  <span class="comment"># 残差标准误，之前使用summary函数查看模型结果时，已经给出该值</span></span><br><span class="line">  <span class="comment"># 这里也再计算一遍</span></span><br><span class="line">  s &lt;- sqrt(sum((y - fit.value)^<span class="number">2</span>) / (length(y) - <span class="number">2</span>))</span><br><span class="line">  <span class="keyword">return</span>(c(r.square = r.square, s = s))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 创建空list，存放相应模型的决定系数和残差标准误</span></span><br><span class="line">model.measure.values &lt;- list()</span><br><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:length(fit.values)) &#123;</span><br><span class="line">  <span class="keyword">if</span> (!is.null(fit.values[[i]])) &#123;</span><br><span class="line">     model.measure.values[[i]] &lt;- ModelMeasure(fit.values[[i]], ratio) </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 查看相应模型的决定系数和残差标准误</span></span><br><span class="line">model.measure.values</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>]]</span><br><span class="line">r.square        s </span><br><span class="line"><span class="number">0.988762</span> <span class="number">0.007621</span> </span><br><span class="line">[[<span class="number">2</span>]]</span><br><span class="line"><span class="literal">NULL</span></span><br><span class="line">[[<span class="number">3</span>]]</span><br><span class="line">r.square        s </span><br><span class="line"> <span class="number">0.95896</span>  <span class="number">0.01456</span> </span><br><span class="line">[[<span class="number">4</span>]]</span><br><span class="line"><span class="literal">NULL</span></span><br><span class="line">[[<span class="number">5</span>]]</span><br><span class="line">r.square        s </span><br><span class="line"> <span class="number">0.95634</span>  <span class="number">0.01502</span></span><br></pre></td></tr></table></figure><p>将输出整理为表格形式：</p><table><thead><tr class="header"><th>模型编号</th><th>1</th><th>3</th><th>5</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(R^2\)</span></td><td>0.988762</td><td>0.95896</td><td>0.95634</td></tr><tr class="even"><td><span class="math inline">\(s\)</span></td><td>0.007621</td><td>0.01456</td><td>0.01502</td></tr></tbody></table><p>可以看到这里计算的残差标准误与使用summary函数查看模型结果时的残差标准误是一致的。通过表格可以看到，在决定系数<span class="math inline">\(R^2\)</span>一行中模型1的值最大，最接近于1；在残差标准误<span class="math inline">\(s\)</span>一行中，模型1的值最小。所以无论不论使用决定系数，还是使用残差标准误，模型1都是在这3个模型中拟合最好的。</p><h2 id="预测">预测</h2><p>选择模型1回归模型对365天内的留存率进行预测，并指出留存率开始低于1%和0.5%时的天数。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用模型1作为回归模型</span></span><br><span class="line">best.model &lt;- model1</span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">predicted &lt;- predict(best.model, data.frame(day = seq(<span class="number">1</span>, <span class="number">365</span>)))</span><br><span class="line"><span class="comment"># 保留4位有效数字</span></span><br><span class="line">predicted &lt;- round(predicted, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 找出留存率低于1%和0.5%的天数</span></span><br><span class="line">(threshold1 &lt;- max(which(predicted &gt;= <span class="number">0.01</span>)))</span><br><span class="line">(threshold2 &lt;- max(which(predicted &gt;= <span class="number">0.005</span>)))</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>] <span class="number">112</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">356</span></span><br></pre></td></tr></table></figure><p>输出结果表示留存率在112之后开始低于1%，在356日之后开始低于0.5%。</p><p>绘制回归曲线在1～365日内的图形</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plot(<span class="number">1</span>:<span class="number">365</span>, predicted, type = <span class="string">"l"</span>, xlim = c(<span class="number">1</span>, <span class="number">375</span>))</span><br><span class="line">threshold1.value &lt;- predicted[threshold1]</span><br><span class="line">threshold2.value &lt;- predicted[threshold2]</span><br><span class="line">points(threshold1, threshold1.value, bg = <span class="string">"yellow"</span>, cex = <span class="number">1.2</span>, pch = <span class="number">21</span>)</span><br><span class="line">points(threshold2, threshold2.value, bg = <span class="string">"yellow"</span>, cex = <span class="number">1.2</span>, pch = <span class="number">21</span>)</span><br><span class="line">text(threshold1, threshold1.value, pos = <span class="number">3</span>, labels = sprintf(<span class="string">"(%d, %.4f)"</span>, threshold1, threshold1.value))</span><br><span class="line">text(threshold2, threshold2.value, pos = <span class="number">3</span>, labels = sprintf(<span class="string">"(%d, %.4f)"</span>, threshold2, threshold2.value))</span><br></pre></td></tr></table></figure> <img title="回归曲线图" data-src="/游戏数据分析/留存率预测/nls.jpg"></div><footer class="post-footer"><div class="post-tags"><a href="/tags/R语言/" rel="tag"><i class="fa fa-tag"></i> R语言</a><a href="/tags/非线性回归/" rel="tag"><i class="fa fa-tag"></i> 非线性回归</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/信用风险分析/信用风险预测-逻辑回归/" rel="prev" title="信用风险预测-逻辑回归">信用风险预测-逻辑回归<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">lwl</p><div class="site-description motion-element" itemprop="description"></div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">18</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">7</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">24</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#留存率预测"><span class="nav-number">1.</span> <span class="nav-text">留存率预测</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#探索性分析"><span class="nav-number">1.1.</span> <span class="nav-text">探索性分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#建立模型"><span class="nav-number">1.2.</span> <span class="nav-text">建立模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型比较"><span class="nav-number">1.3.</span> <span class="nav-text">模型比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预测"><span class="nav-number">1.4.</span> <span class="nav-text">预测</span></a></li></ol></li></ol></div></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span><span class="with-love" id="animate"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">lwl</span></div><div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script src="/lib/jquery/index.js?v=3.4.1"></script><script src="/lib/mediumzoom/medium-zoom.min.js"></script><script src="/lib/lazyload/lozad.min.js?v=1.10.0"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script><script src="/js/affix.js?v=7.3.0"></script><script src="/js/schemes/pisces.js?v=7.3.0"></script><script src="/js/scrollspy.js?v=7.3.0"></script><script src="/js/post-details.js?v=7.3.0"></script><script src="/js/next-boot.js?v=7.3.0"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/local-search.js?v=7.3.0"></script><script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script><script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script></body></html>